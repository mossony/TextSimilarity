{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\TextSimilarity\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:08:00.593373100Z",
     "start_time": "2023-08-20T18:08:00.587372500Z"
    }
   },
   "id": "8e431614e406546"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:09:40.860398600Z",
     "start_time": "2023-08-20T18:09:38.260855Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:09:42.012739900Z",
     "start_time": "2023-08-20T18:09:41.978710900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_train = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"train\")\n",
    "data_test = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"test\")\n",
    "data_dev = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"dev\")\n",
    "\n",
    "# data_train = data_train.select(range(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:09:44.742103600Z",
     "start_time": "2023-08-20T18:09:43.236559900Z"
    }
   },
   "id": "ae7af8128246ec0e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749 1379 1500\n",
      "A plane is taking off.\n",
      "An air plane is taking off.\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train), len(data_test), len(data_dev))\n",
    "print(data_train['sentence1'][0])\n",
    "print(data_train['sentence2'][0])\n",
    "print(data_train['similarity_score'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:09:44.758073200Z",
     "start_time": "2023-08-20T18:09:44.757072500Z"
    }
   },
   "id": "96ac18ce79383423"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SentenceSimilarityModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(SentenceSimilarityModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.regression_head = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        # TODO: After BERT output the encoding, need to add more layers to get the sim_score?\n",
    "        sim_score = self.regression_head(cls_output)\n",
    "        return sim_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T18:09:46.334415200Z",
     "start_time": "2023-08-20T18:09:46.311183300Z"
    }
   },
   "id": "d8f483e62157ac0f"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = SentenceSimilarityModel(model_name)\n",
    "model.to(device)\n",
    "# Assume 'sentences1' and 'sentences2' are your paired sentences\n",
    "# and 'similarity_scores' are your human-annotated similarity scores\n",
    "inputs = tokenizer(data_train['sentence1'], data_train['sentence2'], padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "similarity_scores = torch.tensor(data_train['similarity_score'])\n",
    "\n",
    "batch_size = 64  # You can change the batch size as needed\n",
    "train_data = torch.utils.data.TensorDataset(input_ids, attention_mask, similarity_scores)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# scheduler = StepLR(optimizer, step_size=3, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:23:26.316799100Z",
     "start_time": "2023-08-20T22:23:22.198911500Z"
    }
   },
   "id": "4fb86d6127de3c4f"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 90/90 [01:45<00:00,  1.17s/it, loss=1.75] \n",
      "Epoch 2/5: 100%|██████████| 90/90 [02:04<00:00,  1.38s/it, loss=0.577]\n",
      "Epoch 3/5: 100%|██████████| 90/90 [01:53<00:00,  1.26s/it, loss=0.415]\n",
      "Epoch 4/5: 100%|██████████| 90/90 [01:53<00:00,  1.26s/it, loss=0.228]\n",
      "Epoch 5/5: 100%|██████████| 90/90 [01:49<00:00,  1.22s/it, loss=0.26] \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Inner loop for mini-batches with tqdm progress bar\n",
    "    loop = tqdm(train_loader, leave=True)  # leave=True ensures that the progress bars are replaced with new ones at each epoch\n",
    "    for batch in loop:\n",
    "        input_ids, attention_mask, labels = [item.to(device) for item in batch]\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted_similarity_scores = model(input_ids, attention_mask)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_similarity_scores.squeeze(), labels.float())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the progress bar description\n",
    "        loop.set_description(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    # scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:32:53.713675500Z",
     "start_time": "2023-08-20T22:23:27.720682600Z"
    }
   },
   "id": "9c4e8d67e595e841"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7153321790198485\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've already loaded the validation data into `data_dev`\n",
    "inputs_dev = tokenizer(data_dev['sentence1'], data_dev['sentence2'], padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids_dev = inputs_dev['input_ids']\n",
    "attention_mask_dev = inputs_dev['attention_mask']\n",
    "similarity_scores_dev = torch.tensor(data_dev['similarity_score'])\n",
    "\n",
    "dev_data = torch.utils.data.TensorDataset(input_ids_dev, attention_mask_dev, similarity_scores_dev)\n",
    "dev_loader = DataLoader(dev_data, batch_size=batch_size)\n",
    "\n",
    "def compute_validation_loss(model, dev_loader, loss_fn):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        for batch in dev_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "\n",
    "            # If using GPU\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predicted_similarity_scores = model(input_ids, attention_mask)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(predicted_similarity_scores.squeeze(), labels.float())\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Compute the validation loss\n",
    "val_loss = compute_validation_loss(model, dev_loader, loss_fn)\n",
    "print(f'Validation Loss: {val_loss}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:33:04.975883300Z",
     "start_time": "2023-08-20T22:33:02.049831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def get_similarity_score(model, sentence1, sentence2, tokenizer):\n",
    "    \"\"\"\n",
    "    Compute the similarity score for two sentences using a trained model.\n",
    "    \n",
    "    Args:\n",
    "    model (nn.Module): The trained model.\n",
    "    sentence1 (str): The first sentence.\n",
    "    sentence2 (str): The second sentence.\n",
    "    tokenizer (BertTokenizer): The tokenizer.\n",
    "    \n",
    "    Returns:\n",
    "    float: The similarity score between the two sentences.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentences\n",
    "    inputs = tokenizer(sentence1, sentence2, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    print(input_ids, attention_mask)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    with torch.no_grad():  # Deactivates autograd, reduces memory usage and speeds up computations\n",
    "        sim_score = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Convert the similarity score to a single float and return it\n",
    "    return sim_score.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:33:20.330729600Z",
     "start_time": "2023-08-20T22:33:20.322730100Z"
    }
   },
   "id": "10af71efc470c69c"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 10117, 15045, 17835, 10124, 18020, 11222, 10105, 64321,   119,\n",
      "           102,   138, 14025, 13000, 25926, 10124, 37897, 10226, 13000, 11222,\n",
      "         10105, 12361, 10162,   119,   102]], device='cuda:0') tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='cuda:0')\n",
      "Similarity Score: 0.4855020046234131\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "sentence1 = \"The black dog is running through the snow.\"\n",
    "sentence2 = \"A race car driver is driving his car through the mud.\"\n",
    "similarity_score = get_similarity_score(model, sentence1, sentence2, tokenizer)\n",
    "\n",
    "print(\"Similarity Score:\", similarity_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:42:31.976140100Z",
     "start_time": "2023-08-20T22:42:31.859089Z"
    }
   },
   "id": "37c5df6964530e7f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight tensor([[-9.8576e-03, -8.6186e-02, -1.9419e-02, -5.8699e-02, -6.8748e-02,\n",
      "          1.2147e-03,  7.1022e-02, -7.2849e-02, -1.3442e-02, -8.5468e-02,\n",
      "         -8.9295e-02,  8.7370e-02,  9.4590e-02,  2.0929e-02,  4.2192e-02,\n",
      "          8.0297e-02, -3.4667e-03, -7.2941e-02, -4.7128e-03, -2.2853e-02,\n",
      "         -1.3593e-01, -1.3975e-02,  1.0986e-01,  8.2436e-02,  9.2455e-02,\n",
      "          1.4437e-02, -9.6229e-02,  7.1659e-04, -2.0385e-03,  8.1047e-02,\n",
      "         -6.9119e-02,  6.8833e-03, -5.5303e-02,  7.0761e-02, -8.9178e-03,\n",
      "         -4.5705e-02,  1.3978e-02, -2.7497e-02,  1.3547e-01,  8.3929e-02,\n",
      "          1.0169e-01,  2.1116e-02, -1.4193e-02, -1.0319e-02, -4.5860e-02,\n",
      "         -1.1053e-02,  9.9705e-02,  2.9289e-02, -8.8129e-02,  1.2879e-01,\n",
      "          1.1823e-01, -1.0034e-02, -1.4605e-01, -1.5781e-03,  4.6638e-02,\n",
      "          5.7965e-03, -7.6121e-02,  9.6768e-04, -5.2582e-02, -1.6819e-03,\n",
      "         -5.5089e-02,  1.1726e-01, -1.1702e-02,  1.1708e-02, -7.1751e-03,\n",
      "          9.1619e-02, -5.5705e-02, -2.7183e-02,  8.4559e-02,  1.3083e-01,\n",
      "         -1.0302e-01, -9.6062e-02, -6.0098e-02,  4.1560e-02,  2.4586e-02,\n",
      "          1.2850e-02,  2.2427e-02, -1.3275e-05,  8.4591e-02, -9.4298e-03,\n",
      "          8.3520e-03, -6.4623e-02,  1.9839e-02,  5.7584e-02,  8.7317e-02,\n",
      "          3.0814e-02, -1.2614e-02,  6.8936e-02,  2.8403e-02,  1.4515e-02,\n",
      "          1.0515e-02, -5.4990e-02,  3.3628e-02, -8.4548e-02,  2.1076e-02,\n",
      "          5.4681e-02,  5.1962e-02, -1.3969e-03, -1.0365e-01, -1.1892e-01,\n",
      "          5.0866e-03, -4.8471e-02, -9.8672e-02, -1.6092e-02,  4.6087e-03,\n",
      "         -4.1909e-03,  8.7326e-02,  3.4955e-02, -6.5983e-02, -1.8001e-02,\n",
      "         -7.9518e-02, -1.5150e-03, -1.0970e-02, -4.8136e-03, -5.0581e-02,\n",
      "          1.0279e-01, -5.5106e-03, -1.0361e-02,  7.4960e-02, -5.4935e-03,\n",
      "         -8.2625e-02, -6.6406e-02, -1.5553e-03,  3.0365e-02,  9.6329e-02,\n",
      "          8.2235e-02, -3.1230e-02,  6.0312e-02, -4.7876e-02, -8.7878e-02,\n",
      "         -4.3562e-02, -1.9141e-03,  1.2767e-02,  8.8392e-03, -7.6454e-02,\n",
      "         -1.4849e-02,  5.7344e-02, -6.7934e-02, -4.4298e-02, -1.5678e-02,\n",
      "          6.6269e-03,  1.0057e-02,  1.0585e-01,  7.3202e-02,  9.8873e-03,\n",
      "         -1.2683e-03, -3.6783e-03,  1.3593e-02, -6.1629e-04, -1.3232e-01,\n",
      "          7.8445e-02,  1.8197e-02,  4.7195e-03, -2.3476e-02,  7.6772e-02,\n",
      "         -1.0800e-01, -1.3244e-03,  1.0096e-01,  9.3250e-02,  8.5874e-03,\n",
      "         -1.0092e-02, -8.2768e-02,  5.1803e-02, -6.6323e-03, -5.4841e-02,\n",
      "         -8.5147e-02, -6.5004e-02,  1.1560e-03,  6.0810e-02,  6.0436e-02,\n",
      "          3.9397e-04,  1.2756e-01, -6.5934e-02,  5.2262e-02,  9.7772e-02,\n",
      "         -3.0192e-02, -9.7797e-02,  2.5396e-03, -1.0569e-02,  1.1205e-02,\n",
      "         -9.8901e-03, -7.9099e-02, -4.9322e-02, -4.1443e-02, -7.9071e-02,\n",
      "         -2.2407e-02, -4.2267e-03,  1.5432e-02,  4.1093e-03, -6.8773e-02,\n",
      "          1.0938e-01, -7.8822e-03, -5.8802e-02,  7.2211e-02, -1.0946e-01,\n",
      "          8.7812e-03,  8.9542e-02,  3.9196e-03, -7.9932e-02,  8.5361e-03,\n",
      "         -1.1073e-02, -3.2879e-03, -3.6785e-02,  1.6058e-02,  1.0834e-01,\n",
      "          1.2680e-03,  9.3008e-03,  3.9669e-03, -8.9631e-03, -7.5552e-02,\n",
      "         -1.8766e-01,  1.8332e-02,  9.2628e-04, -1.0625e-01,  1.0020e-01,\n",
      "         -7.3578e-02,  2.1082e-03,  9.0574e-02, -4.6200e-05,  8.2492e-03,\n",
      "          7.5990e-04, -1.2570e-02,  8.6199e-02,  4.3717e-03, -5.2016e-03,\n",
      "         -1.6344e-03, -5.7764e-02,  2.5955e-02, -8.7747e-02,  8.0774e-02,\n",
      "         -1.9766e-02, -8.9401e-03, -1.3981e-01, -3.5522e-02, -7.9572e-03,\n",
      "          7.9430e-02, -8.1106e-02,  8.7170e-02,  7.5898e-02,  1.1583e-01,\n",
      "          9.4265e-02, -9.1245e-02, -1.2383e-02,  3.5451e-03, -1.0311e-02,\n",
      "          1.0057e-01,  1.7903e-02,  7.3803e-02, -7.9389e-02,  5.9488e-02,\n",
      "         -5.2395e-02,  1.0045e-02, -6.4436e-02, -3.9107e-03, -5.0698e-03,\n",
      "         -6.0085e-02, -7.2764e-02,  3.7430e-02, -6.1267e-02,  8.0990e-04,\n",
      "          1.0313e-01,  5.4162e-03, -2.5156e-02,  6.5072e-02,  1.4786e-02,\n",
      "          1.8244e-02,  2.7860e-02,  2.5191e-03,  1.1641e-02, -7.3516e-03,\n",
      "         -1.8383e-02,  1.3595e-02, -1.0176e-03,  9.7250e-04, -1.1778e-01,\n",
      "         -9.3496e-03, -8.4611e-03, -8.1624e-02,  8.8288e-02,  2.5547e-03,\n",
      "          8.3830e-02,  9.7842e-03, -4.4773e-02, -6.6281e-04, -7.0268e-03,\n",
      "         -5.6157e-03, -1.5183e-02,  1.3892e-02,  9.3143e-02,  3.9864e-02,\n",
      "         -1.0768e-02, -1.9815e-02,  8.1643e-02,  8.7249e-02, -1.1413e-02,\n",
      "          1.1029e-02,  8.2773e-02, -1.1194e-01, -3.3446e-03,  9.3401e-03,\n",
      "          5.0978e-03,  9.7289e-02,  9.9250e-02, -7.7767e-03,  1.7719e-02,\n",
      "         -1.0152e-01, -7.4573e-03, -7.6533e-02, -6.4717e-03, -6.7029e-02,\n",
      "         -2.4027e-03,  4.5388e-02, -1.2616e-02, -4.7758e-03,  9.3761e-02,\n",
      "         -5.5967e-04, -6.3563e-03, -1.1252e-02, -2.4084e-03,  2.0441e-02,\n",
      "         -5.2418e-02, -1.4626e-02,  9.1914e-02, -1.1341e-01, -1.4465e-01,\n",
      "          1.6112e-03,  5.8441e-02, -6.3310e-03,  3.3993e-03, -4.5333e-02,\n",
      "         -5.8811e-04, -1.2373e-02,  1.4273e-02, -2.8189e-03, -1.0656e-01,\n",
      "          2.9586e-03, -6.8771e-02,  1.4723e-02,  1.8455e-03,  6.6289e-02,\n",
      "          1.3108e-03,  2.6511e-04,  1.8770e-03, -7.4086e-02,  8.4045e-03,\n",
      "         -4.3228e-02,  9.7370e-03,  2.4740e-02, -5.0352e-02, -1.6717e-02,\n",
      "         -4.8374e-02, -6.8672e-03, -1.5240e-03,  1.1795e-01, -7.9078e-02,\n",
      "          1.5815e-02,  3.6760e-02,  1.0663e-01,  1.4418e-02, -4.5511e-02,\n",
      "         -1.6920e-02, -7.1002e-02,  7.6736e-03,  8.3411e-02, -9.2229e-02,\n",
      "          1.2676e-01,  7.2777e-02, -7.1512e-03, -3.8344e-03,  6.7476e-02,\n",
      "         -1.0251e-02, -4.6158e-02,  6.9231e-02,  6.1533e-02,  8.9004e-02,\n",
      "          1.1994e-02, -3.5699e-03, -5.3157e-02, -9.7950e-02,  9.0423e-02,\n",
      "         -1.2357e-01,  9.2037e-03,  2.3019e-02, -5.7555e-02,  7.2472e-03,\n",
      "          2.7326e-02, -1.1395e-02, -1.0198e-01,  2.1897e-02,  6.1311e-02,\n",
      "         -1.6655e-02,  1.0429e-01, -1.1549e-02,  3.4867e-02,  1.1653e-02,\n",
      "          2.4563e-02, -2.4645e-03, -1.6170e-02, -7.6482e-02,  2.7005e-03,\n",
      "         -9.6910e-03,  1.4841e-02, -1.2494e-03,  2.5595e-02,  5.7998e-02,\n",
      "          3.1020e-02, -1.5876e-02, -9.0797e-04,  1.0186e-01, -1.1526e-01,\n",
      "          6.5671e-03,  1.0862e-01, -1.5517e-01,  1.0840e-01,  6.6131e-02,\n",
      "         -7.9774e-02,  5.3472e-02, -1.1075e-01, -1.1215e-01,  1.1190e-01,\n",
      "         -5.1251e-02, -5.6511e-03, -1.1267e-01,  7.3124e-02,  1.1214e-01,\n",
      "         -9.7339e-02, -1.1548e-01,  1.0725e-01, -8.8296e-02, -5.2326e-02,\n",
      "          5.8040e-02, -1.4529e-04, -1.8038e-02, -3.9090e-03,  2.3917e-02,\n",
      "         -7.1741e-03,  3.9652e-02,  1.1609e-01, -2.5337e-02, -2.2044e-02,\n",
      "         -9.0900e-02, -8.8508e-02,  5.5808e-02, -1.0192e-01, -1.3864e-03,\n",
      "          3.4147e-02, -4.8491e-02,  1.2141e-02,  1.0293e-03, -4.9850e-03,\n",
      "         -6.8641e-02,  6.0594e-02,  2.4969e-02, -1.0475e-02, -1.2017e-01,\n",
      "          1.4126e-02,  9.2146e-02, -6.9322e-02,  1.4816e-03, -5.6470e-02,\n",
      "         -8.0406e-02, -8.9633e-02,  2.3121e-02, -8.0703e-03, -5.7264e-02,\n",
      "         -1.2339e-01,  1.1670e-03, -2.4394e-03,  1.2325e-01,  4.8431e-02,\n",
      "         -1.0817e-01,  1.0551e-02,  9.4470e-02, -1.0213e-01,  2.5951e-02,\n",
      "         -1.0007e-02,  1.2680e-02,  6.7219e-02, -1.7359e-03, -2.3444e-02,\n",
      "         -7.6385e-02, -9.7380e-02,  1.0981e-02,  6.9055e-02,  8.2024e-02,\n",
      "         -1.2903e-03,  7.8116e-02,  9.7232e-02, -6.8715e-03,  9.5992e-02,\n",
      "         -5.5104e-02, -1.1767e-01,  7.8206e-03, -2.7589e-02,  9.4680e-02,\n",
      "         -9.8922e-02, -1.6687e-03, -1.0387e-01, -1.0299e-01, -6.4909e-03,\n",
      "          1.0365e-02,  3.3610e-02,  4.0552e-02, -5.2978e-02,  7.1895e-02,\n",
      "          5.2312e-03,  1.3002e-02,  3.0301e-02, -4.4438e-03, -4.6151e-02,\n",
      "         -9.6417e-02,  1.3161e-02, -1.3028e-02,  3.4676e-03,  4.6143e-03,\n",
      "         -5.5115e-03, -5.2337e-03, -3.7015e-02, -5.3039e-02,  6.9092e-02,\n",
      "         -2.2160e-02, -3.5610e-02,  6.4767e-02, -1.1786e-02,  1.2393e-03,\n",
      "          8.0419e-02,  8.5545e-02,  1.0899e-01,  1.8313e-03, -6.8542e-02,\n",
      "          8.6934e-02,  1.4453e-01,  9.3187e-02, -1.4853e-03,  9.7655e-03,\n",
      "         -1.0017e-01,  1.1877e-02,  7.0142e-02,  4.0333e-02, -1.2836e-03,\n",
      "          7.9348e-03, -1.0257e-01,  9.1771e-02,  3.6847e-03, -1.3809e-02,\n",
      "         -9.2060e-02,  1.1957e-01,  5.2357e-02, -1.9101e-03, -5.9161e-02,\n",
      "          5.8682e-02, -5.1232e-02, -7.8034e-02,  3.3999e-03,  1.3949e-02,\n",
      "          1.0795e-01,  9.8299e-02,  3.6016e-03,  3.6945e-03, -9.0591e-02,\n",
      "         -1.1471e-01, -6.6983e-02, -1.0473e-01, -1.0013e-01,  1.0857e-01,\n",
      "          9.4641e-03, -1.1044e-04, -2.9179e-03, -6.2699e-02,  8.9999e-03,\n",
      "         -1.7786e-02,  7.7358e-02, -1.7415e-02,  3.6797e-03, -4.7715e-02,\n",
      "          7.0617e-02, -4.6629e-02,  5.0562e-03, -5.5697e-03,  7.8764e-03,\n",
      "         -9.7079e-03,  8.5019e-02,  7.1209e-02,  4.1934e-04,  2.4989e-03,\n",
      "         -1.9587e-02,  1.0539e-01,  1.2888e-01,  1.1775e-02, -1.8992e-02,\n",
      "         -4.5663e-03, -5.1402e-03, -1.9299e-02, -1.2046e-02, -1.6202e-03,\n",
      "         -6.0941e-02, -1.2529e-02, -1.9134e-02,  2.1527e-02, -1.0902e-02,\n",
      "          6.4315e-02,  8.0091e-02, -5.5986e-03, -1.8715e-02, -5.9448e-02,\n",
      "          9.0053e-02, -4.3528e-02, -5.9672e-03,  9.7391e-02, -1.6807e-02,\n",
      "         -5.4488e-03, -8.9970e-02,  7.2042e-03,  8.7676e-03,  1.3333e-03,\n",
      "          1.5655e-02, -2.4947e-02, -3.5108e-03,  9.2183e-02, -6.5519e-02,\n",
      "          2.4997e-03,  4.0818e-03, -4.6069e-02,  1.9647e-02, -2.8630e-02,\n",
      "         -5.6047e-02, -3.2109e-02,  7.1225e-02,  1.0450e-02,  4.9473e-02,\n",
      "         -7.0030e-02,  8.9348e-02, -1.0219e-01,  9.2209e-02,  3.5790e-02,\n",
      "          2.5765e-02, -9.1634e-03,  9.1628e-02,  1.4707e-03,  7.8780e-03,\n",
      "          1.0314e-01,  5.7465e-02,  9.5110e-03, -3.0653e-02, -5.0720e-02,\n",
      "          1.1753e-01,  5.7380e-02, -4.7917e-02,  1.4569e-02, -7.9418e-02,\n",
      "         -9.6842e-02,  1.0900e-01,  1.0988e-01, -1.9778e-02, -2.7241e-03,\n",
      "          8.1384e-02, -1.2885e-03, -5.9817e-03, -1.1835e-01, -7.3625e-02,\n",
      "         -9.5133e-03,  1.4372e-02,  9.8204e-02, -7.1483e-03, -2.7375e-02,\n",
      "          3.2452e-03,  3.6035e-02,  8.5510e-02, -7.7906e-02,  5.0101e-03,\n",
      "          5.5636e-03,  1.4443e-03,  4.3288e-02, -2.2575e-02,  1.1555e-02,\n",
      "          2.2023e-02,  9.4136e-03,  8.0758e-03, -3.6227e-02, -1.2276e-02,\n",
      "          2.9909e-02, -9.2431e-03, -3.6318e-02,  8.4674e-02, -1.4300e-02,\n",
      "          2.8587e-04, -2.4099e-03, -4.5909e-02, -2.1460e-02,  4.3246e-03,\n",
      "         -8.9723e-02, -1.3755e-02,  1.1379e-03,  1.1598e-01, -1.1246e-01,\n",
      "          6.3790e-02,  8.9400e-02, -1.4356e-02,  1.9586e-02,  8.7901e-02,\n",
      "         -5.8542e-02, -1.3088e-02, -1.3763e-01,  4.7794e-04, -5.6660e-02,\n",
      "         -1.6591e-02,  2.6629e-03,  1.8753e-02, -9.2115e-02,  7.6391e-02,\n",
      "         -3.8274e-03, -3.1237e-02,  1.2327e-01, -9.4432e-03,  6.1655e-02,\n",
      "         -3.3458e-02, -1.7794e-02,  8.4205e-02,  1.3537e-02,  3.0498e-04,\n",
      "         -2.3949e-02, -4.0346e-02, -1.0444e-01, -1.6486e-02, -7.5639e-02,\n",
      "          5.1134e-03,  3.9758e-02, -7.7138e-03,  7.3739e-04, -5.3153e-02,\n",
      "         -6.9935e-03,  1.1609e-02, -4.7069e-03, -4.1549e-02,  1.6780e-02,\n",
      "         -7.8711e-03,  7.3489e-02,  1.7040e-02, -1.1001e-01,  7.5199e-03,\n",
      "          5.9404e-02, -1.3405e-01,  9.4166e-02,  1.2520e-02, -1.1530e-01,\n",
      "         -7.4385e-02, -1.4101e-02, -1.4967e-02,  7.5024e-02, -1.0320e-01,\n",
      "         -1.0457e-01,  1.2204e-02, -1.6128e-02,  1.1469e-02, -1.1182e-02,\n",
      "         -1.0732e-03, -3.9863e-03,  1.1074e-02,  7.8353e-02,  8.0793e-03,\n",
      "          8.8112e-03,  5.8750e-02, -1.4787e-02,  6.7993e-03, -2.9198e-02,\n",
      "         -4.4014e-02,  6.2727e-04, -3.8022e-02]], device='cuda:0')\n",
      "bias tensor([0.0996], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.regression_head.named_parameters():\n",
    "    print(name, param.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:03:46.824750600Z",
     "start_time": "2023-08-20T22:03:46.745750600Z"
    }
   },
   "id": "191e147b258c8af1"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3802]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sample_tensor = torch.randn(size=(1, model.bert.config.hidden_size)).to(device)  # Create a random tensor with the appropriate size\n",
    "with torch.no_grad():\n",
    "    print(model.regression_head(sample_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:04:48.989236200Z",
     "start_time": "2023-08-20T22:04:48.975204400Z"
    }
   },
   "id": "318d1200b5651a7b"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "input_ids_tensor = torch.tensor([[  101, 14535, 10105, 13192, 10393, 10115,   112,   188, 10590, 33626,\n",
    "           119,   102, 10117, 12229,   118, 33626, 46291, 46935, 13663,   102]])\n",
    "attention_mask_tensor = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "# Check if CUDA is available and move tensors to GPU if available, else keep them on CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids_tensor = input_ids_tensor.to(device)\n",
    "attention_mask_tensor = attention_mask_tensor.to(device)\n",
    "\n",
    "# Move your model to the same device\n",
    "model = model.to(device)\n",
    "\n",
    "# Pass tensors through model.bert\n",
    "with torch.no_grad():\n",
    "    outputs = model.bert(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "\n",
    "# The outputs are a tuple. The first entry is the hidden states and the second (optional) is the pooled CLS token\n",
    "hidden_states = outputs.last_hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:33:11.882542200Z",
     "start_time": "2023-08-20T22:33:11.835776300Z"
    }
   },
   "id": "ffe5771c9817adf1"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0487,  0.0999, -0.0588,  ...,  0.0827, -0.0242, -0.2865],\n",
      "         [ 0.0220,  0.0951, -0.0224,  ...,  0.1847, -0.0065, -0.3365],\n",
      "         [ 0.0509,  0.0744, -0.0815,  ...,  0.1365, -0.0614, -0.3466],\n",
      "         ...,\n",
      "         [ 0.1415,  0.1406, -0.1518,  ...,  0.2477, -0.0445, -0.3622],\n",
      "         [ 0.0645,  0.1314, -0.1587,  ...,  0.1056, -0.0793, -0.3208],\n",
      "         [ 0.0803,  0.1288, -0.1300,  ...,  0.0326, -0.1209, -0.3192]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T22:33:12.799775Z",
     "start_time": "2023-08-20T22:33:12.777747400Z"
    }
   },
   "id": "316e3f8d6fd39357"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e094a1dfe998c9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d55d0967caf2a66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Expand the scale from sentence similarity to paragraph/article similartity using trained sentence model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43d9a56313e6d0ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "envname",
   "language": "python",
   "display_name": "TextSimilarity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
